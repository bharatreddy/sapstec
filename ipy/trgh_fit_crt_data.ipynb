{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from aacgmv2 import convert_mlt\n",
    "import feather\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tecMinCutoff = 10.\n",
    "delTecCutoff = 0.\n",
    "delMlatCutoff = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dst_date  dst_index   dateStr hour\n",
       "0 2011-01-01 01:00:00      -11.0  20110101   01\n",
       "1 2011-01-01 02:00:00      -11.0  20110101   02\n",
       "2 2011-01-01 03:00:00       -9.0  20110101   03\n",
       "3 2011-01-01 04:00:00       -5.0  20110101   04\n",
       "4 2011-01-01 05:00:00       -3.0  20110101   05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dst index vals from wdc kyoto website\n",
    "# create a list of dates with monthly freq\n",
    "date_dst_arr = []\n",
    "dst_val = []\n",
    "dst_time_del = datetime.timedelta(hours = 1)\n",
    "start_date = datetime.datetime(2011,1,1)\n",
    "end_date = datetime.datetime(2014,12,31)\n",
    "daterange = pandas.date_range(start_date, end_date, freq=\"M\")\n",
    "for dt in daterange:\n",
    "    if dt.month <= 9:\n",
    "            monthStr = \"0\" + str(dt.month)\n",
    "    else:\n",
    "        monthStr = str(dt.month)\n",
    "    if dt.year >= 2016:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_realtime\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    elif ( (dt.year >= 2014) and (dt.year <= 2015) ):\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_provisional\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    else:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_final\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    conn = urllib.urlopen(currUrl)\n",
    "    htmlSource = conn.read()\n",
    "    soup = bs4.BeautifulSoup(htmlSource, 'html.parser')\n",
    "    dataResObj = soup.find(\"pre\", { \"class\" : \"data\" })\n",
    "    # get the data as a list of strings after removing white space\n",
    "    lines = dataResObj.text.strip().splitlines()\n",
    "    for line in lines[6:]:\n",
    "        columns = line.split()\n",
    "        if len( columns ) > 0. :\n",
    "            date_dst_arr.append( datetime.datetime( \\\n",
    "                dt.year, dt.month, int(columns[0]), 1 ) )\n",
    "            for cols in range( len( columns[1:] ) ) :\n",
    "                try:\n",
    "                    inNumberFloatTest = float(columns[cols + 1])\n",
    "                except:\n",
    "                    # split these cols as well and work on them!\n",
    "                    try:\n",
    "                        missedCols = columns[cols + 1].split(\"-\")[1:]\n",
    "                        if len(missedCols) >= 1:\n",
    "                            for mcols in missedCols:\n",
    "                                dst_val.append( -1*float( mcols ) )\n",
    "                                # now since we added the date earlier we need to be\n",
    "                                # careful about appending date values\n",
    "                                if ( len(date_dst_arr) != len(dst_val) ):\n",
    "                                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "                    except:\n",
    "                        print \"something wrong with messed up vals!-->\", columns[cols + 1]\n",
    "                        continue\n",
    "                    continue\n",
    "                # I have to do this because of the messed up way Kyoto puts up the latest dst value..\n",
    "                # mixed with 9999 (fillers) like if latest dst is 1 then Kyoto puts it as 199999.....\n",
    "                if len( columns[ cols + 1 ] ) < 5 :\n",
    "                    dst_val.append( float( columns[ cols + 1 ] ) )\n",
    "                elif ( len( columns[ cols + 1 ] ) > 5 and columns[ cols + 1 ][0:3] != '999' ) :\n",
    "                    mixed_messed_dst = ''\n",
    "                    for jj in range(5) :\n",
    "                        if columns[ cols + 1 ][jj] != '9' :\n",
    "                            mixed_messed_dst = mixed_messed_dst + columns[ cols + 1 ][jj]\n",
    "\n",
    "                    if mixed_messed_dst != '-' :\n",
    "                        dst_val.append( float( mixed_messed_dst ) )\n",
    "                    else :\n",
    "                        dst_val.append( float( 'nan' ) )\n",
    "                else :\n",
    "                    dst_val.append( float( 'nan' ) )\n",
    "                if cols > 0 :\n",
    "                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "# convert dst data to a dataframe\n",
    "dstDF = pandas.DataFrame(\n",
    "    {'dst_date': date_dst_arr,\n",
    "     'dst_index': dst_val\n",
    "    })\n",
    "dstDF[\"dateStr\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%H'))\n",
    "dstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"/Users/bharat/Dropbox/tec/trghBnds/\"\n",
    "fitDir = \"/Users/bharat/Dropbox/tec/trghCoeffs/\"\n",
    "colNames = [ \"mlatEqu\", \"tecEqu\", \"mlon\",\\\n",
    "            \"mlatPol\", \"tecPol\", \"date\",\\\n",
    "            \"mlatMin\", \"tecMin\", \"mlt\", \"mlonAdjst\" ]\n",
    "frames = []\n",
    "# cnt = 0\n",
    "for root, dirs, files in os.walk(baseDir):\n",
    "    for fNum, fName in enumerate(files):\n",
    "        currInpLosFile = root + fName\n",
    "        bndDF = pandas.read_csv(currInpLosFile, delim_whitespace=True,\\\n",
    "                                    header=None, names=colNames,\\\n",
    "                                infer_datetime_format=True,\\\n",
    "                                parse_dates=[\"date\"])\n",
    "        frames.append( bndDF )\n",
    "\n",
    "finBndDF = pandas.concat( frames )\n",
    "finBndDF[\"normMLT\"] = [x-24 if x >= 12 else x\\\n",
    "                         for x in finBndDF['mlt']]\n",
    "finBndDF[\"delTecEqu\"] = finBndDF[\"tecEqu\"] - finBndDF[\"tecMin\"]\n",
    "finBndDF[\"delTecPol\"] = finBndDF[\"tecPol\"] - finBndDF[\"tecMin\"]\n",
    "finBndDF[\"delMlat\"] = finBndDF[\"mlatPol\"] - finBndDF[\"mlatEqu\"]\n",
    "finBndDF[\"timeStr\"] = finBndDF[\"date\"].dt.strftime('%H%M').astype(int)\n",
    "# # discard dates where delTecEqu and delTecPol are -ve\n",
    "# finBndDF[\"dateStr\"] = finBndDF[\"date\"].dt.strftime('%Y%m%d')\n",
    "discrdDatesDelTec = finBndDF[ (finBndDF[\"delTecEqu\"] < delTecCutoff) |\\\n",
    "                   (finBndDF[\"delTecPol\"] < delTecCutoff) ][\"date\"].values\n",
    "finBndDF = finBndDF[ ~finBndDF[\"date\"].isin(discrdDatesDelTec) ].reset_index(drop=True)\n",
    "# Discard those dates where tecMin is greater than 10.\n",
    "discrdDatestecMin = finBndDF[ (finBndDF[\"tecMin\"] > tecMinCutoff) ][\"date\"].values\n",
    "finBndDF = finBndDF[ ~finBndDF[\"date\"].isin(discrdDatestecMin) ].reset_index(drop=True)\n",
    "# Discard locations where delMlat < 0.\n",
    "finBndDF = finBndDF[ finBndDF[\"delMlat\"] > 0. ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To estimate the boundary we\n",
    "# fit first order harmonics!\n",
    "def trough_fit_harmonic(mlt, a0, c1, s1, phiC1, phiS1):\n",
    "    phiC = (2*numpy.pi/24.) * mlt + phiC1\n",
    "    phiS = (2*numpy.pi/24.) * mlt + phiS1\n",
    "    cosTerm = c1 * numpy.cos(phiC)\n",
    "    sinTerm = s1 * numpy.sin(phiS)\n",
    "    return a0 + cosTerm + sinTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110101\n",
      "110110\n"
     ]
    }
   ],
   "source": [
    "# Read the fitting coefficients to estimate location\n",
    "# of the trough from them.\n",
    "\n",
    "coeffCols = [ \"a0EquBnd\", \"a0MinTrgh\", \"a0PolBnd\",\\\n",
    "             \"c1EquBnd\", \"c1MinTrgh\", \"c1PolBnd\",\\\n",
    "             \"phiC1EquBnd\", \"phiC1MinTrgh\", \"phiC1PolBnd\",\\\n",
    "             \"phiS1EquBnd\", \"phiS1MinTrgh\", \"phiS1PolBnd\",\\\n",
    "             \"s1EquBnd\", \"s1MinTrgh\", \"s1PolBnd\", \"trghPredTime\" ]\n",
    "\n",
    "coeffFrames = []\n",
    "\n",
    "# Arrays to store data\n",
    "mlatEquArr = []\n",
    "tecEquArr = []\n",
    "mlonArr = []\n",
    "mlatPolArr = []\n",
    "tecPolArr = []\n",
    "dateArr = []\n",
    "mlatMinArr = []\n",
    "tecMinArr = []\n",
    "mltArr = []\n",
    "mlonAdjstArr = []\n",
    "normMLTArr = []\n",
    "timeStrArr = []\n",
    "\n",
    "\n",
    "dateStrArr = []\n",
    "\n",
    "goodDatesList = finBndDF[\"date\"].values\n",
    "for nd, gd in enumerate(goodDatesList):\n",
    "    ts = pandas.to_datetime(str(gd)) \n",
    "    yr = ts.strftime('%Y')\n",
    "    mt = ts.strftime('%m')\n",
    "    dt = ts.strftime('%d')\n",
    "    if int(mt) < 10:\n",
    "        mt = mt[-1]\n",
    "    if int(dt) < 10:\n",
    "        dt = dt[-1]\n",
    "    cDtStr = ts.strftime('%y%m%d')\n",
    "    if cDtStr not in dateStrArr:\n",
    "        print cDtStr\n",
    "        dateStrArr.append(cDtStr)\n",
    "    fName = fitDir + \"bnd-coeffs\" + yr + \"-\" +\\\n",
    "                mt + \"-\" + dt + \".txt\"\n",
    "    coeffDF = pandas.read_csv(fName, delim_whitespace=True,\\\n",
    "                                    header=None, names=coeffCols,\\\n",
    "                                infer_datetime_format=True,\\\n",
    "                                parse_dates=[\"trghPredTime\"])\n",
    "    # need to estimate location of trough between the MLT range where\n",
    "    # we could calculate trough bnds. Get that range first!!!\n",
    "    currBndDF = finBndDF[ finBndDF[\"date\"] == gd ]\n",
    "#     print currBndDF[\"mlon\"].values\n",
    "#     nMlonStart = numpy.min( currBndDF[\"mlon\"].values )\n",
    "#     nMlonEnd = numpy.max( currBndDF[\"mlon\"].values )\n",
    "    for cMlon in currBndDF[\"mlon\"].values:\n",
    "        cpMlt = round( convert_mlt( cMlon,\\\n",
    "                                    ts , m2a=False ) )\n",
    "        if cpMlt >= 12 :\n",
    "            nMlt = cpMlt - 24.\n",
    "        else:\n",
    "            nMlt = cpMlt\n",
    "        selCoeffDF = coeffDF[ coeffDF[\"trghPredTime\"] == ts ]\n",
    "        selBndDF = currBndDF[ currBndDF[\"mlon\"] == cMlon ]\n",
    "        minTrghParams = selCoeffDF[ [ \"a0MinTrgh\", \"c1MinTrgh\",\\\n",
    "                                 \"s1MinTrgh\", \"phiC1MinTrgh\",\\\n",
    "                                 \"phiS1MinTrgh\" ] ].values[0]\n",
    "        eqBndParams = selCoeffDF[ [ \"a0EquBnd\", \"c1EquBnd\",\\\n",
    "                               \"s1EquBnd\", \"phiC1EquBnd\",\\\n",
    "                               \"phiS1EquBnd\" ] ].values[0]\n",
    "        polBndParams = selCoeffDF[ [ \"a0PolBnd\", \"c1PolBnd\",\\\n",
    "                                \"s1PolBnd\", \"phiC1PolBnd\",\\\n",
    "                                \"phiS1PolBnd\" ] ].values[0]\n",
    "\n",
    "        minTrghMlat = trough_fit_harmonic(cpMlt, *minTrghParams)\n",
    "        eqBndMlat = trough_fit_harmonic(cpMlt, *eqBndParams)\n",
    "        polBndMlat = trough_fit_harmonic(cpMlt, *polBndParams)\n",
    "        \n",
    "        # store the data into arrays\n",
    "        mlatEquArr.append( eqBndMlat ) \n",
    "        tecEquArr.append( selBndDF[\"tecEqu\"].values[0] ) \n",
    "        mlonArr.append( cMlon ) \n",
    "        mlatPolArr.append( polBndMlat ) \n",
    "        tecPolArr.append( selBndDF[\"tecPol\"].values[0] ) \n",
    "        dateArr.append( gd ) \n",
    "        mlatMinArr.append( minTrghMlat ) \n",
    "        tecMinArr.append( selBndDF[\"tecMin\"].values[0] ) \n",
    "        mltArr.append( cpMlt ) \n",
    "        mlonAdjstArr.append( selBndDF[\"mlonAdjst\"].values[0] ) \n",
    "        normMLTArr.append( nMlt ) \n",
    "        timeStrArr.append( int( ts.strftime('%H%M') ) )\n",
    "\n",
    "trghFitDF = pandas.DataFrame(\n",
    "    {'mlatEqu': mlatEquArr,\n",
    "     'tecEqu': tecEquArr,\n",
    "     'mlon': mlonArr,\n",
    "     'mlatPol': mlatPolArr,\n",
    "     'tecPol': tecPolArr,\n",
    "     'date': dateArr,\n",
    "     'mlatMin': mlatMinArr,\n",
    "     'tecMin': tecMinArr,\n",
    "     'mlt': mltArr,\n",
    "     'mlonAdjst': mlonAdjstArr,\n",
    "     'normMLT': normMLTArr,\n",
    "     'timeStr': timeStrArr\n",
    "    })\n",
    "\n",
    "trghFitDF[\"delTecEqu\"] = trghFitDF[\"tecEqu\"] - trghFitDF[\"tecMin\"]\n",
    "trghFitDF[\"delTecPol\"] = trghFitDF[\"tecPol\"] - trghFitDF[\"tecMin\"]\n",
    "trghFitDF[\"delMlat\"] = trghFitDF[\"mlatPol\"] - trghFitDF[\"mlatEqu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trghFitDF.shape\n",
    "# asyDF = pandas.read_csv( \"../data/Asy_processed.txt\", sep=' ' )\n",
    "# asyDF[\"date\"] = pandas.to_datetime(asyDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "trghFitDF[\"dateStr\"] = trghFitDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "trghFitDF[\"hour\"] = trghFitDF[\"date\"].map(lambda x: x.strftime('%H'))\n",
    "trghFitDF = pandas.merge( trghFitDF, dstDF, on=[\"dateStr\", \"hour\"] )\n",
    "dstBins = [ -150, -50, -25, -10, 10 ]\n",
    "trghFitDF = pandas.concat( [ trghFitDF, \\\n",
    "                    pandas.cut( trghFitDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "trghFitDF.columns = [ \"date\", \"mlatEqu\", \"mlatMin\", \"mlatPol\", \"mlon\",\\\n",
    "                     \"mlonAdjst\", \"mlt\", \"normMLT\", \"tecEqu\", \"tecMin\",\\\n",
    "                     \"tecPol\", \"timeStr\", \"delTecEqu\", \"delTecPol\", \"delMlat\",\\\n",
    "                     \"dateStr\", \"hour\", \"dst_date\", \"dst_index\", \"dst_bin\" ]\n",
    "print trghFitDF.head()\n",
    "feather.write_dataframe(trghFitDF, '../data/trghBndDst-fits.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
