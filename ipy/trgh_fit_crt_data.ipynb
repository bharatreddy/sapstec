{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "from aacgmv2 import convert_mlt\n",
    "import feather\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tecMinCutoff = 10.\n",
    "delTecCutoff = 0.\n",
    "delMlatCutoff = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20110101</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dst_date  dst_index   dateStr hour\n",
       "0 2011-01-01 01:00:00      -11.0  20110101   01\n",
       "1 2011-01-01 02:00:00      -11.0  20110101   02\n",
       "2 2011-01-01 03:00:00       -9.0  20110101   03\n",
       "3 2011-01-01 04:00:00       -5.0  20110101   04\n",
       "4 2011-01-01 05:00:00       -3.0  20110101   05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dst index vals from wdc kyoto website\n",
    "# create a list of dates with monthly freq\n",
    "date_dst_arr = []\n",
    "dst_val = []\n",
    "dst_time_del = datetime.timedelta(hours = 1)\n",
    "start_date = datetime.datetime(2011,1,1)\n",
    "end_date = datetime.datetime(2014,12,31)\n",
    "daterange = pandas.date_range(start_date, end_date, freq=\"M\")\n",
    "for dt in daterange:\n",
    "    if dt.month <= 9:\n",
    "            monthStr = \"0\" + str(dt.month)\n",
    "    else:\n",
    "        monthStr = str(dt.month)\n",
    "    if dt.year >= 2016:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_realtime\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    elif ( (dt.year >= 2014) and (dt.year <= 2015) ):\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_provisional\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    else:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_final\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    conn = urllib.urlopen(currUrl)\n",
    "    htmlSource = conn.read()\n",
    "    soup = bs4.BeautifulSoup(htmlSource, 'html.parser')\n",
    "    dataResObj = soup.find(\"pre\", { \"class\" : \"data\" })\n",
    "    # get the data as a list of strings after removing white space\n",
    "    lines = dataResObj.text.strip().splitlines()\n",
    "    for line in lines[6:]:\n",
    "        columns = line.split()\n",
    "        if len( columns ) > 0. :\n",
    "            date_dst_arr.append( datetime.datetime( \\\n",
    "                dt.year, dt.month, int(columns[0]), 1 ) )\n",
    "            for cols in range( len( columns[1:] ) ) :\n",
    "                try:\n",
    "                    inNumberFloatTest = float(columns[cols + 1])\n",
    "                except:\n",
    "                    # split these cols as well and work on them!\n",
    "                    try:\n",
    "                        missedCols = columns[cols + 1].split(\"-\")[1:]\n",
    "                        if len(missedCols) >= 1:\n",
    "                            for mcols in missedCols:\n",
    "                                dst_val.append( -1*float( mcols ) )\n",
    "                                # now since we added the date earlier we need to be\n",
    "                                # careful about appending date values\n",
    "                                if ( len(date_dst_arr) != len(dst_val) ):\n",
    "                                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "                    except:\n",
    "                        print \"something wrong with messed up vals!-->\", columns[cols + 1]\n",
    "                        continue\n",
    "                    continue\n",
    "                # I have to do this because of the messed up way Kyoto puts up the latest dst value..\n",
    "                # mixed with 9999 (fillers) like if latest dst is 1 then Kyoto puts it as 199999.....\n",
    "                if len( columns[ cols + 1 ] ) < 5 :\n",
    "                    dst_val.append( float( columns[ cols + 1 ] ) )\n",
    "                elif ( len( columns[ cols + 1 ] ) > 5 and columns[ cols + 1 ][0:3] != '999' ) :\n",
    "                    mixed_messed_dst = ''\n",
    "                    for jj in range(5) :\n",
    "                        if columns[ cols + 1 ][jj] != '9' :\n",
    "                            mixed_messed_dst = mixed_messed_dst + columns[ cols + 1 ][jj]\n",
    "\n",
    "                    if mixed_messed_dst != '-' :\n",
    "                        dst_val.append( float( mixed_messed_dst ) )\n",
    "                    else :\n",
    "                        dst_val.append( float( 'nan' ) )\n",
    "                else :\n",
    "                    dst_val.append( float( 'nan' ) )\n",
    "                if cols > 0 :\n",
    "                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "# convert dst data to a dataframe\n",
    "dstDF = pandas.DataFrame(\n",
    "    {'dst_date': date_dst_arr,\n",
    "     'dst_index': dst_val\n",
    "    })\n",
    "dstDF[\"dateStr\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%H'))\n",
    "dstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseDir = \"/home/bharat/Documents/code/data/trghBnds/\"\n",
    "fitDir = \"/home/bharat/Documents/code/data/trghCoeffs/\"\n",
    "colNames = [ \"mlatEqu\", \"tecEqu\", \"mlon\",\\\n",
    "            \"mlatPol\", \"tecPol\", \"date\",\\\n",
    "            \"mlatMin\", \"tecMin\", \"mlt\", \"mlonAdjst\" ]\n",
    "frames = []\n",
    "# cnt = 0\n",
    "for root, dirs, files in os.walk(baseDir):\n",
    "    for fNum, fName in enumerate(files):\n",
    "        currInpLosFile = root + fName\n",
    "        bndDF = pandas.read_csv(currInpLosFile, delim_whitespace=True,\\\n",
    "                                    header=None, names=colNames,\\\n",
    "                                infer_datetime_format=True,\\\n",
    "                                parse_dates=[\"date\"])\n",
    "        frames.append( bndDF )\n",
    "\n",
    "finBndDF = pandas.concat( frames )\n",
    "finBndDF[\"normMLT\"] = [x-24 if x >= 12 else x\\\n",
    "                         for x in finBndDF['mlt']]\n",
    "finBndDF[\"delTecEqu\"] = finBndDF[\"tecEqu\"] - finBndDF[\"tecMin\"]\n",
    "finBndDF[\"delTecPol\"] = finBndDF[\"tecPol\"] - finBndDF[\"tecMin\"]\n",
    "finBndDF[\"delMlat\"] = finBndDF[\"mlatPol\"] - finBndDF[\"mlatEqu\"]\n",
    "finBndDF[\"timeStr\"] = finBndDF[\"date\"].dt.strftime('%H%M').astype(int)\n",
    "# # discard dates where delTecEqu and delTecPol are -ve\n",
    "# finBndDF[\"dateStr\"] = finBndDF[\"date\"].dt.strftime('%Y%m%d')\n",
    "discrdDatesDelTec = finBndDF[ (finBndDF[\"delTecEqu\"] < delTecCutoff) |\\\n",
    "                   (finBndDF[\"delTecPol\"] < delTecCutoff) ][\"date\"].values\n",
    "finBndDF = finBndDF[ ~finBndDF[\"date\"].isin(discrdDatesDelTec) ].reset_index(drop=True)\n",
    "# Discard those dates where tecMin is greater than 10.\n",
    "discrdDatestecMin = finBndDF[ (finBndDF[\"tecMin\"] > tecMinCutoff) ][\"date\"].values\n",
    "finBndDF = finBndDF[ ~finBndDF[\"date\"].isin(discrdDatestecMin) ].reset_index(drop=True)\n",
    "# Discard locations where delMlat < 0.\n",
    "finBndDF = finBndDF[ finBndDF[\"delMlat\"] > 0. ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To estimate the boundary we\n",
    "# fit first order harmonics!\n",
    "def trough_fit_harmonic(mlt, a0, c1, s1, phiC1, phiS1):\n",
    "    phiC = (2*numpy.pi/24.) * mlt + phiC1\n",
    "    phiS = (2*numpy.pi/24.) * mlt + phiS1\n",
    "    cosTerm = c1 * numpy.cos(phiC)\n",
    "    sinTerm = s1 * numpy.sin(phiS)\n",
    "    return a0 + cosTerm + sinTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-36e8e945c2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnMlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpMlt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mselCoeffDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoeffDF\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcoeffDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trghPredTime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mselBndDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrBndDF\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcurrBndDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mlon\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcMlon\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mminTrghParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselCoeffDF\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"a0MinTrgh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"c1MinTrgh\"\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m\"s1MinTrgh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"phiC1MinTrgh\"\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m\"phiS1MinTrgh\"\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0meqBndParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselCoeffDF\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m\"a0EquBnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"c1EquBnd\"\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0;34m\"s1EquBnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"phiC1EquBnd\"\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0;34m\"phiS1EquBnd\"\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2093\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1668\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   3962\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 3964\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3848\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   3849\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 3850\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   3851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1022\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/algorithms.pyc\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# check for promotion based on types only (do this first because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# it's faster than computing a mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_promote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m                 \u001b[0;31m# check if promotion is actually required based on indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/types/cast.pyc\u001b[0m in \u001b[0;36m_maybe_promote\u001b[0;34m(dtype, fill_value)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetimetz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Read the fitting coefficients to estimate location\n",
    "# of the trough from them.\n",
    "\n",
    "coeffCols = [ \"a0EquBnd\", \"a0MinTrgh\", \"a0PolBnd\",\\\n",
    "             \"c1EquBnd\", \"c1MinTrgh\", \"c1PolBnd\",\\\n",
    "             \"phiC1EquBnd\", \"phiC1MinTrgh\", \"phiC1PolBnd\",\\\n",
    "             \"phiS1EquBnd\", \"phiS1MinTrgh\", \"phiS1PolBnd\",\\\n",
    "             \"s1EquBnd\", \"s1MinTrgh\", \"s1PolBnd\", \"trghPredTime\" ]\n",
    "\n",
    "coeffFrames = []\n",
    "\n",
    "# Arrays to store data\n",
    "mlatEquArr = []\n",
    "tecEquArr = []\n",
    "mlonArr = []\n",
    "mlatPolArr = []\n",
    "tecPolArr = []\n",
    "dateArr = []\n",
    "mlatMinArr = []\n",
    "tecMinArr = []\n",
    "mltArr = []\n",
    "mlonAdjstArr = []\n",
    "normMLTArr = []\n",
    "timeStrArr = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "goodDatesList = finBndDF[\"date\"].values\n",
    "for nd, gd in enumerate(goodDatesList):\n",
    "    ts = pandas.to_datetime(str(gd)) \n",
    "    yr = ts.strftime('%Y')\n",
    "    mt = ts.strftime('%m')\n",
    "    dt = ts.strftime('%d')\n",
    "    if int(mt) < 10:\n",
    "        mt = mt[-1]\n",
    "    if int(dt) < 10:\n",
    "        dt = dt[-1]\n",
    "    fName = fitDir + \"bnd-coeffs\" + yr + \"-\" +\\\n",
    "                mt + \"-\" + dt + \".txt\"\n",
    "    coeffDF = pandas.read_csv(fName, delim_whitespace=True,\\\n",
    "                                    header=None, names=coeffCols,\\\n",
    "                                infer_datetime_format=True,\\\n",
    "                                parse_dates=[\"trghPredTime\"])\n",
    "    # need to estimate location of trough between the MLT range where\n",
    "    # we could calculate trough bnds. Get that range first!!!\n",
    "    currBndDF = finBndDF[ finBndDF[\"date\"] == gd ]\n",
    "#     print currBndDF[\"mlon\"].values\n",
    "#     nMlonStart = numpy.min( currBndDF[\"mlon\"].values )\n",
    "#     nMlonEnd = numpy.max( currBndDF[\"mlon\"].values )\n",
    "    for cMlon in currBndDF[\"mlon\"].values:\n",
    "        cpMlt = round( convert_mlt( cMlon,\\\n",
    "                                    ts , m2a=False ) )\n",
    "        if cpMlt >= 12 :\n",
    "            nMlt = cpMlt - 24.\n",
    "        else:\n",
    "            nMlt = cpMlt\n",
    "        selCoeffDF = coeffDF[ coeffDF[\"trghPredTime\"] == ts ]\n",
    "        selBndDF = currBndDF[ currBndDF[\"mlon\"] == cMlon ]\n",
    "        minTrghParams = selCoeffDF[ [ \"a0MinTrgh\", \"c1MinTrgh\",\\\n",
    "                                 \"s1MinTrgh\", \"phiC1MinTrgh\",\\\n",
    "                                 \"phiS1MinTrgh\" ] ].values[0]\n",
    "        eqBndParams = selCoeffDF[ [ \"a0EquBnd\", \"c1EquBnd\",\\\n",
    "                               \"s1EquBnd\", \"phiC1EquBnd\",\\\n",
    "                               \"phiS1EquBnd\" ] ].values[0]\n",
    "        polBndParams = selCoeffDF[ [ \"a0PolBnd\", \"c1PolBnd\",\\\n",
    "                                \"s1PolBnd\", \"phiC1PolBnd\",\\\n",
    "                                \"phiS1PolBnd\" ] ].values[0]\n",
    "\n",
    "        minTrghMlat = trough_fit_harmonic(cpMlt, *minTrghParams)\n",
    "        eqBndMlat = trough_fit_harmonic(cpMlt, *eqBndParams)\n",
    "        polBndMlat = trough_fit_harmonic(cpMlt, *polBndParams)\n",
    "        \n",
    "        # store the data into arrays\n",
    "        mlatEquArr.append( eqBndMlat ) \n",
    "        tecEquArr.append( selBndDF[\"tecEqu\"].values[0] ) \n",
    "        mlonArr.append( cMlon ) \n",
    "        mlatPolArr.append( polBndMlat ) \n",
    "        tecPolArr.append( selBndDF[\"tecPol\"].values[0] ) \n",
    "        dateArr.append( gd ) \n",
    "        mlatMinArr.append( minTrghMlat ) \n",
    "        tecMinArr.append( selBndDF[\"tecMin\"].values[0] ) \n",
    "        mltArr.append( cpMlt ) \n",
    "        mlonAdjstArr.append( selBndDF[\"mlonAdjst\"].values[0] ) \n",
    "        normMLTArr.append( nMlt ) \n",
    "        timeStrArr.append( int( ts.strftime('%H%M') ) )\n",
    "\n",
    "trghFitDF = pandas.DataFrame(\n",
    "    {'mlatEqu': mlatEquArr,\n",
    "     'tecEqu': tecEquArr,\n",
    "     'mlon': mlonArr,\n",
    "     'mlatPol': mlatPolArr,\n",
    "     'tecPol': tecPolArr,\n",
    "     'date': dateArr,\n",
    "     'mlatMin': mlatMinArr,\n",
    "     'tecMin': tecMinArr,\n",
    "     'mlt': mltArr,\n",
    "     'mlonAdjst': mlonAdjstArr,\n",
    "     'normMLT': normMLTArr,\n",
    "     'timeStr': timeStrArr\n",
    "    })\n",
    "\n",
    "trghFitDF[\"delTecEqu\"] = trghFitDF[\"tecEqu\"] - trghFitDF[\"tecMin\"]\n",
    "trghFitDF[\"delTecPol\"] = trghFitDF[\"tecPol\"] - trghFitDF[\"tecMin\"]\n",
    "trghFitDF[\"delMlat\"] = trghFitDF[\"mlatPol\"] - trghFitDF[\"mlatEqu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trghFitDF.shape\n",
    "# asyDF = pandas.read_csv( \"../data/Asy_processed.txt\", sep=' ' )\n",
    "# asyDF[\"date\"] = pandas.to_datetime(asyDF[\"datetimeStr\"], format='%Y%m%d-%H-%M')\n",
    "trghFitDF[\"dateStr\"] = trghFitDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "trghFitDF[\"hour\"] = trghFitDF[\"date\"].map(lambda x: x.strftime('%H'))\n",
    "trghFitDF = pandas.merge( trghFitDF, dstDF, on=[\"dateStr\", \"hour\"] )\n",
    "dstBins = [ -150, -50, -25, -10, 10 ]\n",
    "trghFitDF = pandas.concat( [ trghFitDF, \\\n",
    "                    pandas.cut( trghFitDF[\"dst_index\"], \\\n",
    "                               bins=dstBins ) ], axis=1 )\n",
    "trghFitDF.columns = [ \"date\", \"mlatEqu\", \"mlatMin\", \"mlatPol\", \"mlon\",\\\n",
    "                     \"mlonAdjst\", \"mlt\", \"normMLT\", \"tecEqu\", \"tecMin\",\\\n",
    "                     \"tecPol\", \"timeStr\", \"delTecEqu\", \"delTecPol\", \"delMlat\",\\\n",
    "                     \"dateStr\", \"hour\", \"dst_date\", \"dst_index\", \"dst_bin\" ]\n",
    "print trghFitDF.head()\n",
    "feather.write_dataframe(trghFitDF, '../data/trghBndDst-fits.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
